{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename='pune_india.osm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tags(filename):\n",
    "    tags={}\n",
    "    for event,elem in ET.iterparse(filename):\n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag]+=1\n",
    "        else:\n",
    "            tags[elem.tag]=1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 8048,\n",
       " 'nd': 1702582,\n",
       " 'node': 1419019,\n",
       " 'osm': 1,\n",
       " 'relation': 2182,\n",
       " 'tag': 306838,\n",
       " 'way': 270406}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tags(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if re.match(lower,element.get(\"k\"))!=None:\n",
    "            keys[\"lower\"]+=1\n",
    "        elif re.match(lower_colon,element.get(\"k\"))!=None:\n",
    "            keys[\"lower_colon\"]+=1\n",
    "        elif re.match(problemchars,element.get(\"k\"))!=None:\n",
    "            keys[\"problemchars\"]+=1\n",
    "        else:\n",
    "            keys[\"other\"]+=1\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(file):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 299881, 'lower_colon': 6761, 'other': 196, 'problemchars': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_map(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user(element):\n",
    "    return element.get(\"uid\")\n",
    "\n",
    "\n",
    "def process_id(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        user = get_user(element)\n",
    "        if user != None:\n",
    "         users.add(user)\n",
    "        \n",
    "\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(process_id(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"pune_india.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Court\", \"Place\", \"Square\", \"Lane\",\"Chowk\", \"Parkway\",\n",
    "            \"Circle\",\"Marg\",\"Avenue\",\"Nagar\",\"Park\",\"Path\",\"Road\",\"Street\"]\n",
    "\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"st\": \"Street\",\n",
    "            \"street\":\"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"road\": \"Road\",\n",
    "            \"raod\": \"Road\",\n",
    "            \"udyog\": \"Udyog\",\n",
    "            \"chowk\": \"Chowk\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    splitted_name = name.split()\n",
    "    for word in range(len(splitted_name)):\n",
    "        if splitted_name[word] in mapping:\n",
    "            splitted_name[word] = mapping[splitted_name[word]]\n",
    "    name = \" \".join(splitted_name)\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10': set(['Road 10']),\n",
      " '2': set(['Hinjewadi Phase 2']),\n",
      " 'Bypass': set(['NH4 Bypass']),\n",
      " 'Gymkhana': set(['Deccan Gymkhana']),\n",
      " 'J13': set(['Road number 13, sub lane J13']),\n",
      " 'Magarpatta': set(['Magarpatta']),\n",
      " 'Nilakh': set(['Pimple Nilakh']),\n",
      " 'Pashan': set(['Dr. Homi Bhabha Road, Pashan']),\n",
      " 'Rd': set(['Bhajimandai Rd', 'Gulawani Maharaj Rd', 'MIT College Rd']),\n",
      " 'Sheri': set(['Mahadev Nagar, Wadgaon Sheri']),\n",
      " 'Trail': set(['Pashan Hill Trail']),\n",
      " 'raod': set(['katepuram mayur nagari raod'])}\n"
     ]
    }
   ],
   "source": [
    "st_types = audit(SAMPLE_FILE)\n",
    "\n",
    "pprint.pprint(dict(st_types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Road 10 => Road 10\n",
      "Dr. Homi Bhabha Road, Pashan => Dr. Homi Bhabha Road, Pashan\n",
      "Deccan Gymkhana => Deccan Gymkhana\n",
      "Pimple Nilakh => Pimple Nilakh\n",
      "Bhajimandai Rd => Bhajimandai Road\n",
      "Gulawani Maharaj Rd => Gulawani Maharaj Road\n",
      "MIT College Rd => MIT College Road\n",
      "Pashan Hill Trail => Pashan Hill Trail\n",
      "Hinjewadi Phase 2 => Hinjewadi Phase 2\n",
      "Magarpatta => Magarpatta\n",
      "NH4 Bypass => NH4 Bypass\n",
      "Mahadev Nagar, Wadgaon Sheri => Mahadev Nagar, Wadgaon Sheri\n",
      "Road number 13, sub lane J13 => Road number 13, sub lane J13\n",
      "katepuram mayur nagari raod => katepuram mayur nagari Road\n"
     ]
    }
   ],
   "source": [
    " for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import Improving_Street_Names\n",
    "from Improving_Street_Names import update_name, mapping,name\n",
    "Improving_Street_Names.update_name(name, mapping)\n",
    "Improving_Street_Names.mapping\n",
    "OSM_PATH = \"pune_india.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    toc = 0\n",
    "    # YOUR CODE HERE\n",
    "  \n",
    "    if element.tag == 'node':\n",
    "        for i in NODE_FIELDS:\n",
    "            node_attribs[i] = element.attrib[i]\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            node_tags_attribs = {}\n",
    "            temp = LOWER_COLON.search(tag.attrib['k'])\n",
    "            is_pc = PROBLEMCHARS.search(tag.attrib['k'])\n",
    "            if is_pc:\n",
    "                continue\n",
    "            if tag.attrib[\"k\"] == 'addr:street': \n",
    "                node_tags_attribs[\"value\"] = update_name(tag.attrib[\"v\"], mapping)\n",
    "                node_tags_attribs[\"id\"] = element.attrib['id']\n",
    "                node_tags_attribs[\"key\"] = tag.attrib[\"k\"].split(':',1)[1]\n",
    "                node_tags_attribs[\"type\"] = tag.attrib[\"k\"].split(':',1)[0]\n",
    "            elif temp:\n",
    "                split_char = temp.group(1)\n",
    "                split_index = tag.attrib['k'].index(split_char)\n",
    "                type1 = temp.group(1)\n",
    "                node_tags_attribs['id'] = element.attrib['id']\n",
    "                node_tags_attribs['key'] = tag.attrib['k'][split_index+2:]\n",
    "                node_tags_attribs['value'] = tag.attrib['v']\n",
    "                node_tags_attribs['type'] = tag.attrib['k'][:split_index+1]\n",
    "            else:\n",
    "                node_tags_attribs['id'] = element.attrib['id']\n",
    "                node_tags_attribs['key'] = tag.attrib['k']\n",
    "                node_tags_attribs['value'] = tag.attrib['v']\n",
    "                node_tags_attribs['type'] = 'regular'\n",
    "            tags.append(node_tags_attribs)\n",
    "            \n",
    "            \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "        \n",
    "    elif element.tag == 'way':\n",
    "        id = element.attrib['id']\n",
    "        for i in WAY_FIELDS:\n",
    "            way_attribs[i] = element.attrib[i]\n",
    "        for i in element.iter('nd'):\n",
    "            idu = {}\n",
    "            idu['id'] = id\n",
    "            idu['node_id'] = i.attrib['ref']\n",
    "            idu['position'] = toc\n",
    "            toc+=1\n",
    "            way_nodes.append(idu)\n",
    "        for c in element.iter('tag'):\n",
    "            temp = LOWER_COLON.search(c.attrib['k'])\n",
    "            is_pc = PROBLEMCHARS.search(c.attrib['k'])\n",
    "            eu = {}\n",
    "            if is_pc:\n",
    "                continue\n",
    "            if c.attrib['k'] == 'addr:street': \n",
    "                eu['value'] = update_name(c.attrib['v'], mapping)\n",
    "                eu['id'] = id\n",
    "                eu['key'] = c.attrib[\"k\"].split(':',1)[1]\n",
    "                eu['type'] = c.attrib[\"k\"].split(':',1)[0]\n",
    "            elif temp:\n",
    "                split_char = temp.group(1)\n",
    "                split_index = c.attrib['k'].index(split_char)\n",
    "                eu['id'] = id\n",
    "                eu['key'] = c.attrib['k'][split_index+2:]\n",
    "                eu['type'] = c.attrib['k'][:split_index+1]\n",
    "                eu['value'] = c.attrib['v']\n",
    "            else:\n",
    "                eu['id'] = id\n",
    "                eu['key'] = c.attrib['k']\n",
    "                eu['type'] = 'regular'\n",
    "                eu['value'] = c.attrib['v']\n",
    "            tags.append(eu)\n",
    "            \n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file,          codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file,          codecs.open(WAYS_PATH, 'w') as ways_file,          codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file,          codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes:\n",
      "[(1419019,)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from pprint import pprint\n",
    "\n",
    "sqlite_file = 'newmap.db'    # name of the sqlite database file created\n",
    "\n",
    "# Connecting to the database file\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "QUERY = '''\n",
    "SELECT COUNT(*) as count\n",
    "FROM nodes;\n",
    "'''\n",
    "\n",
    "cur.execute(QUERY)\n",
    "\n",
    "result = cur.fetchall()\n",
    "print 'number of nodes:'\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ways:\n",
      "[(270406,)]\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT COUNT(*) as count\n",
    "FROM ways;\n",
    "'''\n",
    "\n",
    "cur.execute(QUERY)\n",
    "\n",
    "result = cur.fetchall()\n",
    "print 'number of ways:'\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 contributing users\n",
      "[(u'singleton', 96623), (u'harishvarma', 60143), (u'jasvinderkaur', 57694), (u'sramesh', 57627), (u'praveeng', 56788), (u'shiva05', 51899), (u'anushapyata', 49530), (u'kranthikumar', 47435), (u'harishk', 43180), (u'saikumar', 40332)]\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    " SELECT id.user, COUNT(*) as num\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) id\n",
    "GROUP BY id.user\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;\n",
    "'''\n",
    "\n",
    "cur.execute(QUERY)\n",
    "\n",
    "result = cur.fetchall()\n",
    "print 'Top 10 contributing users'\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 appearing amenities\n",
      "[(u'restaurant', 241), (u'bank', 179), (u'atm', 140), (u'place_of_worship', 121), (u'cafe', 75), (u'fast_food', 70), (u'hospital', 53), (u'fuel', 45), (u'school', 40), (u'police', 31), (u'pharmacy', 30), (u'toilets', 23), (u'post_office', 16), (u'bus_station', 14), (u'parking', 14)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "QUERY = '''\n",
    " SELECT value, COUNT(*) as num\n",
    "FROM nodes_tags\n",
    "WHERE key='amenity'\n",
    "GROUP BY value\n",
    "ORDER BY num DESC\n",
    "LIMIT 15;\n",
    "'''\n",
    "\n",
    "\n",
    "cur.execute(QUERY)\n",
    "\n",
    "result = cur.fetchall()\n",
    "print'Top 15 appearing amenities'\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place of Worship:\n",
      "[(u'hindu', 76), (u'muslim', 10), (u'christian', 4), (u'sikh', 1)]\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='place_of_worship') wp\n",
    "    ON nodes_tags.id=wp.id\n",
    "WHERE nodes_tags.key='religion'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "\n",
    "\n",
    "cur.execute(QUERY)\n",
    "\n",
    "result_zip2 = cur.fetchall()\n",
    "print 'Place of Worship:'\n",
    "print(result_zip2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Biggest Bank:\n",
      "[(u'Bank of Maharashtra', 16), (u'ICICI Bank', 10), (u'Axis Bank', 9), (u'HDFC Bank', 9), (u'State Bank of India', 9)]\n"
     ]
    }
   ],
   "source": [
    "QUERY = '''\n",
    "SELECT nodes_tags.value, COUNT(*) as num\n",
    "FROM nodes_tags \n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='bank') bk\n",
    "    ON nodes_tags.id=bk.id\n",
    "WHERE nodes_tags.key='name'\n",
    "GROUP BY nodes_tags.value\n",
    "ORDER BY num DESC\n",
    "LIMIT 5;\n",
    "'''\n",
    "\n",
    "\n",
    "cur.execute(QUERY)\n",
    "print '5 Biggest Bank:'\n",
    "result = cur.fetchall()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
